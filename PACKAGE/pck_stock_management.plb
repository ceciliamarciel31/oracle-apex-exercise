create table item(
    item varchar2(25) not null,
    dept number(4) not null,
    item_desc varchar2(25) not null
);

create table loc(
    loc number(10) not null,
    loc_desc varchar2(25) not null
);

create table item_loc_soh(
item varchar2(25) not null,
loc number(10) not null,
dept number(4) not null,
unit_cost number(20,4) not null,
stock_on_hand number(12,4) not null
);


insert into item(item,dept,item_desc)
select level, round(DBMS_RANDOM.value(1,100)), translate(dbms_random.string('a', 20), 'abcXYZ', level) from dual connect by level <= 1000;

--- in average this will take 1s to be executed
insert into loc(loc,loc_desc)
select level+100, translate(dbms_random.string('a', 20), 'abcXYZ', level) from dual connect by level <= 100;

-- in average this will take less than 120s to be executed
insert into item_loc_soh (item, loc, dept, unit_cost, stock_on_hand)
select item, loc, dept, (DBMS_RANDOM.value(5000,50000)), round(DBMS_RANDOM.value(1000,100000))
from item, loc; --ORA-01536: space quota exceeded for tablespace 'APEX_BIGFILE_INSTANCE_TBS3'

insert into item_loc_soh (item, loc, dept, unit_cost, stock_on_hand)
select item, loc, dept, (DBMS_RANDOM.value(5000,50000)), round(DBMS_RANDOM.value(1000,100000))
from item, loc
where rownum < 100;

commit;

--1
--Primary key definition and any other constraint or index suggestion
-- PK: The column item is distinctive for each record in item table, since it's a unique identifier it should be the pk. 
ALTER TABLE item
ADD CONSTRAINT PK_item PRIMARY KEY (item);
-- Index: Tipically indexes should be created according to the necessity of the application itself. Indexes occupy storage space and can slow down operations, so they should only be used to improve query performance where necessary.
-- In this table I'm going to a early optimization and create a index on column dept 

CREATE INDEX idx_dept ON item (dept);

-- PK: The column item is distinctive for each record in loc table, since it's a unique identifier it should be the pk. 
ALTER TABLE loc
ADD CONSTRAINT PK_loc PRIMARY KEY (loc);

-- PK: Using (item, loc) as a composite primary key ensures each row is uniquely identified by the combination of item and location, reflecting the table's purpose of tracking stock for items at specific locations. 
--     Neither item nor loc alone can guarantee uniqueness, as the same item can exist in multiple locations, and each location can hold multiple item
ALTER TABLE item_loc_soh
ADD CONSTRAINT PK_item_loc_soh PRIMARY KEY (item,loc);

-- Index: Create indexes on columns item and loc to improve join performance
CREATE INDEX idx_item ON item_loc_soh (item);
CREATE INDEX idx_loc ON item_loc_soh (loc);
--2
-- Your suggestion for table data management and data access considering the application usage, for example, partition...

-- Partition the ITEM_LOC_SOH table by loc, to only access the relevant partition.
-- Create composite indexes on columns frequently used in filtering or joining operations, like loc and dept. It's important the column order in composite indexes.
-- Using the WITH clause may increase the performance
-- Using the bind variables may increase the performance by decreasing the parse counts
-- Using UNION ALL instead of UNION if they return the same results or if we donâ€™t care about the duplicates
-- Maintain updated table statistics
-- Analyze the query and determine if it is functionally correct.

--3
-- Your suggestion to avoid row contention at table level parameter because of high level of concurrency
-- All the points mentioned above can help to avoid row contention.

--4
--Create a view that can be used at screen level to show only the required fields

-- Partition the ITEM_LOC_SOH table by loc, to only access the relevant partition.
-- Created index idx_item_loc_dept with columns (loc, dept) will help speed up searches.
-- 

CREATE INDEX idx_item_loc_dept ON item_loc_soh (loc, dept);

CREATE VIEW v_stock_item_loc AS
SELECT 
    ils.item,
    i.item_desc,                
    ils.loc,                 
    ils.dept,                 
    ils.stock_on_hand,       
    ils.unit_cost                
FROM 
    item_loc_soh ils
JOIN item i
ON (ils.item = i.item)
JOIN loc l
ON (l.loc = ils.loc);

select * from v_stock_item_loc;


--5
--Create a new table that associates user to existing dept(s)
CREATE TABLE usr (
    user_id NUMBER(10) GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY
    username VARCHAR2(50) NOT NULL UNIQUE
);

CREATE TABLE dept (
    dept NUMBER(10) GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    dept_name VARCHAR2(50) NOT NULL UNIQUE
);

create table usr_dept (
    dept number(4) not null,
    user_id number(10) not null,
    item_desc varchar2(25) not null,
    CONSTRAINT fk_user FOREIGN KEY (user_id) REFERENCES usr(user_id) ON DELETE CASCADE,
    CONSTRAINT fk_dept FOREIGN KEY (dept) REFERENCES dept(dept) ON DELETE CASCADE
);

CREATE INDEX idx_user_dept_user_id ON usr_dept (user_id);
CREATE INDEX idx_user_dept_dept_id ON usr_dept (dept);

--6
-- Create a package with procedure or function that can be invoked by store or all stores to save the item_loc_soh to a new table that will contain the same information plus the stock value per item/loc (unit_cost*stock_on_hand)
-- PCK_STOCK_MANAGEMENT.save_stock_for_store: Procedure to save stock data for a specific store or all stores 
-- If the parameter p_loc is not NULL, we save the data only for that store. If the parameter is NULL, we save the data for all stores.
select max(stock_val) from (
SELECT i.*, round(unit_cost * stock_on_hand,4) stock_val FROM item_loc_soh i);

-- Table item_loc_soh_val with column stock value
create table item_loc_soh_val(
item varchar2(25) not null,
loc number(10) not null,
dept number(4) not null,
unit_cost number(20,4) not null,
stock_on_hand number(12,4) not null,
stock_value number(24,4) not null
);


begin 
PCK_STOCK_MANAGEMENT.save_stock_for_store(p_loc => 109);
end;
/
select * from item_loc_soh_val  where loc = 109;

--7. Create a data filter mechanism that can be used at screen level to filter out the data that user can see accordingly to dept association (created previously)
-- Function GET_GRID_USER_DATA has the user as a parameter and returns a cursor with the list of departments they have access to.

--8. Create a pipeline function to be used in the location list of values (drop down)
CREATE OR REPLACE TYPE type_loc_list AS TABLE OF NUMBER(10);
-- function "GET_LOC_LIST" has the user as a parameter and returns the location list they have access to.

--9. 
--I had to use other data due to having inserted fewer records
EXPLAIN PLAN FOR
select * from ITEM_LOC_SOH where loc = 109 and dept = 43;

SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY); --Error: cannot fetch last explain plan from PLAN_TABLE


--I'm not able to open the execution plan, but I believe that with the index idx_item_loc_dept will significantly improve query performance.

--10. Run the previous method that was created on 6. for all the stores from item_loc_soh to the history table. The entire migration should not take more than 10s to run (don't use parallel hint to solve it :)) 
--I'm not able to chrck the real performance, since I only have part of the records
begin 
PCK_STOCK_MANAGEMENT.save_stock_for_store(p_loc => null);
end;
/

-- 11. Please have a look into the AWR report (AWR.html) in attachment and let us know what is the problem that the AWR is highlighting and potential solution.
-- The AWR report identifies a significant performance issue related to "resmgr:cpu quantum" as the top wait event, accounting for 83.1% of the database time. This suggests that the database is experiencing resource 
-- contention due to CPU resource management.
-- Potential solution:
-- Investigate the SQL statements contributing most to DB time. Optimize these queries to reduce their resource usage.
-- Use Performance Tuning to identify specific SQL or objects contributing to high resource consumption.